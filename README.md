# papers-i-wrote
This is a collection of papers I wrote (or co-wrote)

## [Understanding language - one evaluation at a time](https://github.com/Maaarcocr/papers-i-wrote/blob/master/understanding-language-one.pdf)
In this survey I will firstly introduce the reader to the basic concepts that power the modern NLP research, describing concepts like neural networks, optimizations techniques and word embeddings. Then, I will describe the status of the art of evaluation in the NLP community, what problems exist and solutions. I will conclude exploring by future directions in evaluating NLP systems. 

## [Hyper-parameter tuning and empirical evaluation in Natural Language Processing](https://github.com/Maaarcocr/papers-i-wrote/blob/master/hyper-parameter-tuning-and-evaluation.pdf)

As the field of Natural Language Processing (NLP) continues to mature, with more claimed state-of-the-art results, it has become increasingly difficult to discern between model architecture strength and irrelevant factors. We see our works being developed into a fully integrated framework, which would allow us to compare architectures on different data-sets with automatic hyper-parameter tuning. We introduce a systematic and reproducible method, which allows us to reduce bias. Our black-box optimisation not only leads to computational speedup, but also achieves stronger results than the word2vec default hyper-parameters; achieving a significant 15.9% improvement on a word similarity evaluation metric. We aim to usher in a new trend where future research has greater emphasis on careful empirical experimentation, leading to superior architectures.
